---
title: "Eigenvector Methods for Community Detection in  Hypergraphs"                 
subtitle: "Applied Math Seminar <br> Claremont Center for the Mathematical Sciences"
author: "Dr. <span class = 'author-highlight'>Phil Chodrow</span> <br> Dept. of Mathematics, UCLA <br> Sept 20th, 2021"           
date: ""              
output:                       
  xaringan::moon_reader:         
    lib_dir: libs    
    css: ["../assets/ninpo.css",  "../assets/ninjutsu.css",   "../assets/shinobi.css", "../assets/pc_custom.css"]    
    seal: true   
    self_contained: false  
    nature: 
      ratio: "16:10"
      highlightStyle: github     
      highlightLines: true 
      countIncrementalSlides: false  
---
exclude: true   
<style type="text/css">
code.r{ 
  font-size: 16px; 
}
pre {
  font-size: 16px !important;  
}
</style>
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

---

class: split-two
layout: false

.column.bg-main1[
.content[ 
  ## Graphs and Hypergraphs
 
  <br> 
  A .alert[graph] consists of a set of nodes $\mathcal{N}$ and a set of edges $\mathcal{E}$. Each edge in $\mathcal{E}$ is a set of two nodes. 

<br> <br> <br> <br> <br>
  In .alert[hypergraphs], edges in $\mathcal{E}$ can contain *any number* of nodes.     
]

]

.column[
  .vmiddle[
  <img src="img/graph-hypergraph.png" width=100%></img>
  ] 
]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Examples of Hypergraphs

  

]

.column.bg-main2[.vmiddle[
  <br>
]]


---

class: split-two
layout: false

.column.bg-main1[
  
  ## Examples of Hypergraphs

<br> <br> 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  

]

.column.bg-main2[.vmiddle[
  <img src="img/social-interaction.jpeg" width=100%></img> 
]]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Examples of Hypergraphs

<br> <br> 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  - .alert[**Collaboration**]: nodes are collaborators, edges are projects (papers, legislation, etc). 
  

]

.column.bg-main2[.vmiddle[
  <img src="img/teamwork.jpeg" width=100%></img> 
]]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Examples of Hypergraphs

<br> <br> 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  - .alert[**Collaboration**]: nodes are collaborators, edges are projects (papers, legislation, etc). 
  - .alert[**Co-presence**]: nodes are chemical compounds, edges are drugs formed from those compounds.

]

.column.bg-main2[.vmiddle[
  <img src="img/mccoy.png" width=100%></img> 
]]

---




layout: false
class: split-two

.column.bg-main1[
  ### The Hypergraph Community Detection Problem 

  Given a hypergraph data set, assign each node to a .alert[**community**] (or "cluster") of "related" nodes. 
  <br> <br>
  "*Related*": often interpreted as "*densely interconnected.*"
<br> <br>
  Applications in social network analysis, drug discovery, image processing, data visualization...

  
  <div class="footnote">
  .alert2[One review]: <br> <b>PSC</b>, N. Veldt, A. R. Benson, (2021). Generative hypergraph clustering: from blockmodels to modularity, <i>Science Advances</i>, 7:eabh1303
</div>

  
]
.column[.content.vmiddle[.stretch[
  <img src="img/detection-1.png" width=100%>
]]]

---

layout: true
class: split-two middle 
 
.column[
  .split-three[ 
  .row.bg-main1[.content.vmiddle[.font_medium[  
.alert[**Graph community detection**] with eigenvectors.
  ]]]     
  .row.bg-main2[.content.vmiddle[.font_medium[
.alert[**Hashimoto operators**] and eigenvector methods for hypergraphs.  
  ]]] 
  .row.bg-main3[.content.vmiddle[.font_medium[ 
.alert[**Detectability thresholds**] and open questions. 
  ]]]
]] 

.column[.center[.stretch[
  {{content}} 
]]]
 
---
class: hide-row2-col1 hide-row3-col1 hide-row4-col1 hide-row5-col1


  <img src="img/pol-blogs.png" width=60%>

  <div class="footnote">
  Image from <a href="http://allthingsgraphed.com/2014/10/09/visualizing-political-polarization/"> All Things Graphed </a> 
  </div>




---
class: hide-row3-col1 hide-row4-col1   hide-row5-col1 
<br> <br> <br> 
<img src="img/hypergraph-nonbacktracking.png" width=100%>
<br> 

---
class: hide-row4-col1 hide-row5-col1 
<br> <br> <br> <br>
<img src="img/heatmap-exp-1-with-curve.png" width=100%> 

---

class: fade-row2-col1 fade-row3-col1 fade-row4-col1 fade-row5-col1

  <img src="img/pol-blogs.png" width=60%>

  <div class="footnote">
    Image from <a href="http://allthingsgraphed.com/2014/10/09/visualizing-political-polarization/"> All Things Graphed </a> 
  </div>
---

class: bg-main2
layout: false
background-image: url(img/opportunity.jpeg)
background-size: contain

---

class: split-two
layout: false

.column[
  ## The graph...

.center[
  <img src="img/pol-blogs.png" width=58%>
]
]
.column[

  ## ...and the matrix
  
  .center[
  <br> 
  <img src="img/sample-matrix.png" width=100%>
  ]

]

---

class: split-two
layout: false

.column.bg-main1[
  ## Modeling Clustered Graphs

  Take $n$ nodes and divide them into two groups $a$ and $b$. 

  For each pair of nodes $i$ and $j$, draw an edge with probability 

  $$p_{ij} = \begin{cases} p &\quad i,j \text{ are in the same group} \\ q &\quad i,j \text{ are in different groups} \end{cases}$$

  We can represent the result as an adjacency matrix $\mathbf{A}$, where 

  $$a_{ij} = \begin{cases} 1 &\quad (i,j) \in \mathcal{E} \\ 0 &\quad  \text{otherwise} \end{cases}$$
]

.column[.vmiddle[.center[

<img src="img/sbm-matrix.png" width=80%>
]]
]

---

class: split-two
layout: false

.column.bg-main1[
  ### Clusters from Eigenvectors

.font_smaller[
  Leading eigenvectors of $\mathbf{P}$:

  $\mathbf{v}_1 = {\underbrace{(1,1,\ldots,1,1)}_{2n \text{ copies}}}^T$ <br> 
  $\lambda_1 = \frac{n}{2}(p + q)$.

<br>
  $\mathbf{v}_2 = (\underbrace{1,1,\ldots,1}_{n \text{ copies } (a)}, \underbrace{-1,-1,\ldots,-1}_{n \text{ copies } (b)})$ <br>
  $\lambda_2 = \frac{n}{2}(p - q)$.


  .alert[Results from random matrix theory]: the "interesting" eigenvalues/vectors of $\mathbf{A}$ are very close to the "interesting" eigenvalues/vectors of $\mathbf{P}$ with high probability as $n$ grows large.  
]
]

.column[.vmiddle[.center[

<img src="img/sbm-matrix.png" width=80%>
]]
]

---

class: split-two
layout: false

.column.bg-main1[
  ## An Algorithm

Suppose we don't know the cluster labels. We can estimate them (under the right conditions) using $\mathbf{v}_2$. 

<br>
.alert[Adjacency Spectral Clustering]

1. Compute the second-largest eigenvector $\mathbf{v}_2$ of $\mathbf{A}$. 
2. If $\mathbf{v}_{2i} > 0$, guess that node $i$ is in group $a$, otherwise in group $b$. 

Variations on this work for other graph matrices. 
]

.column[.center[

<img src="img/sbm-clustering.png" width=75%>
]]

---

layout: true
class: split-two middle 
 
.column[
  .split-three[ 
  .row.bg-main1[.content.vmiddle[.font_medium[  
.alert[**Graph community detection**] with eigenvectors. 
  ]]]     
  .row.bg-main2[.content.vmiddle[.font_medium[
.alert[**Hashimoto operators**] and eigenvector methods for hypergraphs.  
  ]]] 
  .row.bg-main3[.content.vmiddle[.font_medium[ 
.alert[**Detectability thresholds**] and open questions. 
  ]]]
]] 

.column[.center[
  {{content}} 
]]

---
class: fade-row1-col1 fade-row3-col1
<br> <br> <br> 
<img src="img/hypergraph-nonbacktracking.png" width=100%>
<br> 

---

class: split-two
layout: false

.column.bg-main1[

### Matrices for Hypergraphs? 

The adjacency matrix $\mathbf{A}$ is .alert[two-dimensional], and is therefore good for capturing .alert[pairwise] relationships. 

For hypergraphs, there are options: 

- Transform into a graph (loses information)
- Represent adjacency via "tensors" (hyperarrays):

$$a_{ijk} = \begin{cases} 1 &\quad (i,j,k)\in \mathcal{E} \\ 0 &\quad \text{otherwise...}\end{cases}$$


- Other (please specify)

]

.column[
  <br>
  <img src="img/graph-hypergraph.png" width=100%>
]




---
class: split-50 bg-main1 
layout: false 
 
.row[ 
.split-three[
.column[<br><br>
  <img src="img/jamie_portrait.jpeg" width=90%> 
  ]
.column[<br><br>
  <img src="img/eikmeier-3.png" width=90%> 
]
.column[<br><br>
  <img src="img/phil_portrait.jpeg" width=90%>   
] 

]
]
.row[ 
.split-three[
.column[<br>
  .font_large[.alert[<nobr>Jamie Haddock</nobr>]]
  <nobr>Mathematics</nobr> <br> Harvey Mudd College      
  .alert2[@jamie_hadd]
]
.column[<br>
  .font_large[.alert[<nobr>Nicole Eikmeier</nobr>]]
   Computer Science <br> Grinnell College      
   .alert2[@NicoleEikmeier]
]
.column[<br>
  .font_large[.alert[<nobr>Phil Chodrow</nobr>]]
  <nobr>Mathematics</nobr> <br> UCLA
  <br> .alert2[@PhilChodrow] <br>
]
]
]

---

class: split-two
layout: false


.column.bg-main1[
## The Hashimoto Operator

The adjacency matrix is $n\times n$,  operates on nodes. 

The .alert[Hashimoto operator] operates on .alert2[edge-node pairs]: 

Let $(e_1, p_1) \rightarrow (e_2, p_2)$ if: 

- $p_1 \in e_1$ and $p_2 \in e_2$
- $p_1 \in e_2 \setminus p_2$
- $e_1 \neq e_2$

Then, 

.font_smaller[ .font_smaller[
$$\mathbf{B}[(e_1, p_1), (e_2, p_2)] = \begin{cases} 1 &\quad (e_1, p_1) \rightarrow (e_2, p_2) \\ 
0 &\quad \text{otherwise.}\end{cases}$$
]]]

.column[
<br> <br> <br> 
<img src="img/hypergraph-nonbacktracking.png" width=100%>
]

---

class: split-two
layout: false


.column.bg-main1[
## The Hashimoto Operator

<br> 

Popularized (for graphs) in Hashimoto K. (1990), *Int. J. Math.* 1, 381–396

First formulated for hypergraphs by Storm, C. K. (2006). *The Electronic Journal of Combinatorics*.

"Rediscovered" for hypergraphs by Angelini, M. C., Caltagirone, F., Krzakala, F., & Zdeborová, L. (2015), *Allerton Conference*.

*Also often called the "nonbacktracking operator/matrix."*

]

.column[
<br> <br> <br> 
<img src="img/hypergraph-nonbacktracking.png" width=100%>
]

---

class: split-two
layout: false


.column.bg-main1[
## The Hashimoto Operator

<br> 

Connected to prime cycles and zeta functions on graphs. 

Same construction works for hypergraphs with edges of different sizes. 

.alert[Second eigenvector] is correlated with communities, if corresponding eigenvalue is real.  
  - Needs to be aggregated to node level
 
]

.column[.content.vmiddle[.stretch[
<img src="img/eigen-illustration.png" width=100%>   
]]]

---

class: split-two
layout: false


.column.bg-main1[
## Issue \# 1: Computation

$\mathbf{B}$ is indexed by edge-node pairs. 

So, $\mathbf{B}$ is of size $m\langle k\rangle \times m\langle k\rangle$, where $m$ is the number of edges and $\langle k \rangle$ is the average edge size. 

The `contact-high-school` data set we'll study soon has $n = 327$ nodes, $m = 7,818$ hyperedges, and $\langle k\rangle = 2.4$. 


So, $m\langle k \rangle = 7,818 \times 2.4 \approx 19,000$, which is already a pretty big matrix. And this is *small* data!

 
]

.column[.content.vmiddle[.stretch[
<img src="img/hypergraph-nonbacktracking.png" width=100%>   
]]]

---

class: bg-main2
background-image: url("img/large-matrix.jpeg")
background-size: contain



---

class: bg-main2
layout: false

## Linear Algebra to the Rescue

**Theorem (PSC, JH, NE '21)**: Under mild conditions, if $\lambda$ is an eigenvalue of $\mathbf{B},$ then either: 

1. $\lambda \in \{1, -1, -2, \ldots, 1-\bar{k}\}$ and carries no structural information about the hypergraph, or
2. $\lambda$ is an eigenvalue of the matrix 

$$
\mathbf{B}' = \left[\begin{matrix}
  <!-- \mathbf{0} & \mathbb{D} - \mathbf{I}_{\bar{k}n} \\ -->
  <!--   (\mathbf{I}_{\bar{k}}- \mathbf{K}) \otimes \mathbf{I}_n &  \mathbb{A} + (2\mathbf{I}_{\bar{k}} - \mathbf{K})\otimes \mathbf{I}_n -->
\end{matrix}\right] \in \mathbb{R}^{2\bar{k}n\times 2\bar{k}n}\;.
$$

.font_smaller[.font_smaller[
- $\bar{k}$ is the number of distinct edge sizes, $n$ is the number of nodes. 
- $\mathbb{A} \in \mathbb{R}^{\bar{k}n\times \bar{k}n}$ collects adjacency information for each hyperedge size.
- $\mathbb{D} \in \mathbb{R}^{\bar{k}n\times \bar{k}n}$ collects node degrees for each hyperedge size. 
- $\mathbf{K} \in \mathbb{R}^{\bar{k}\times \bar{k}}$ lists possible edge sizes. 
- $\mathbf{I}_{\ell} \in \mathbb{R}^{\ell\times \ell}$ is the matrix identity of size $\ell$. 
- $\otimes$ is the Kronecker product. 
]]

---

class: bg-main2
  

## Proof Sketch

1. $\mathbf{B}$ can be written as $\mathbf{S}\mathbf{T} - \mathbf{R}$ for suitable operators $\mathbf{S}$, $\mathbf{T}$ and $\mathbf{R}$, which also satisfy handy relations like $\mathbf{T}\mathbf{S} = \mathbb{A}$.  
2. Consider $\det(\lambda\mathbf{I} - \mathbf{B})$, substitute $\mathbf{B} = \mathbf{S}\mathbf{T} - \mathbf{R}$, and use the *push-through identity*:
$$
\det(\mathbf{X + \mathbf{Y}\mathbf{Z}}) = \det(\mathbf{X}) \det(\mathbf{I} + \mathbf{Z}\mathbf{X}^{-1}\mathbf{Y})
$$
provided all inverses and products are defined. 
3. Battle through a .alert1[**LOT**] of algebraic simplifications, obtaining 
$$
\det(\lambda \mathbf{I} - \mathbf{B}) = \det(\text{boring part})\det(\lambda\mathbf{I} - \mathbf{B}')\,.
$$ 


.footnote[Approach based on a proof of the the graph Ihara-Bass formula in: <br> M. C. Kempton (2016). Non-backtracking random walks and a weighted Ihara’s theorem. *Open Journal of Discrete Mathematics*
]


---

class: split-two
layout: false


.column.bg-main1[
## Issue \# 1: Computation

<br> <br> 
The `contact-high-school` data set we'll study soon has $n = 327$ nodes, $m = 7,818$ hyperedges, and $\langle k\rangle = 2.4$. 

<br> 
By theorem, can compute eigenvectors in $2n\bar{k} \approx 2,000 \color{#FFD046}{\ll} 19,000 \approx m\langle k\rangle$ dimensions instead.


]

.column[.content.vmiddle[.stretch[
<img src="img/hypergraph-nonbacktracking.png" width=100%>   
]]]

---

class: split-two
layout: true

.column.bg-main1[

  ## First Algorithm

  
  2. Compute the second eigenpair $(\lambda_2, \mathbf{v}_2)$ of $\mathbf{B}'$. 
  3. .alert[If] $\color{#FFD046}{\lambda_2}$ .alert[is] .alert2[real], separate $\mathbf{v}_2 = (\alpha, \beta)$, with $\alpha, \beta \in \mathbb{R}^{n\bar{k}}$. 
  4. If
     $$u_i = \sum_{k = 1}^{\bar{k}}\alpha_{ik} < 0\;,$$
    assign $i$ to cluster $A$, else assign $i$ to cluster $B$. 

(.alert[If] $\color{#FFD046}{\lambda_2}$ .alert[is] .alert2[complex] then this doesn't work, and the story gets pretty interesting! More later.)
]

.column[.content.vmiddle[.stretch[
{{ content }}
]]]

---

class: split-two


<img src="img/eigen-illustration.png" width=100%>   

---

class: split-two


<img src="img/detectability-setup.png" width=100%>   

---

class: split-two


<img src="img/vanilla-heatmap.png" width=100%>   

---

class: split-two
layout: false


.column.bg-main1[
## Issue \# 2: Edge Sizes

As we've just seen, our first spectral algorithm only works well when edges of different sizes carry .alert[similar types of information] about the clusters. 

<br> 

What if edges of different sizes mean different things? 

<br> 

Example: small interactions might be very likely to be within a cluster, but larger interactions might be more likely to be *between* clusters. 

]

.column[.content.vmiddle[.stretch[
<img src="img/different-roles.png" width=100%>   
]]]

---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

  <br>

  
]

---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

  <br>

  ...is the "cavity method" of statistical physics. 

  
]

---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

  <br>

  ...is the "cavity method" of statistical physics. 

  ...is an approximate method for ~~statistical inference~~ Machine Learning®.

  
]

---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

  <br>

  ...is the "cavity method" of statistical physics. 

  ...is an approximate method for ~~statistical inference~~ Machine Learning®.

  ...is a discrete-time dynamical system.  
]

---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

  <br>

  ...is the "cavity method" of statistical physics. 

  ...is an approximate method for ~~statistical inference~~ Machine Learning®.

  ...is a discrete-time dynamical system.  
]

.column[

<br> 
Formally, iterate these updates to convergence: 
<br> 
\begin{align}
\mu_{iR}^{(s)} &\gets \frac{1}{Z_{iR}}\prod_{Q \in \binom{[n]}{|R|}\setminus R} \nu_{Qi}^{(s)} \\ 
\nu_{Ri}^{(s)} &\gets \frac{1}{Z_{Ri}}\sum_{\mathbf{z}:z_i = s}\mathbb{P}(a_R| \mathbb{z}_R)\prod_{j \in R\setminus i} \mu_{jR}^{(z_j)}
\end{align}

.font_smaller[  
$\mu_{iR}^{(s)}$ is "node $i$'s confidence that it belongs to cluster $s$ based on other nodes in tuple $R$."

$Z_{iR}$ is a normalization constant. 

$\mathbb{P}(a_R|\mathbb{z}_R)$ is a statistical model of how likely there are to be $a_R$ edges on tuple $R$ given the cluster labels $\mathbf{z}_R$. 
]
]

---

class: split-two

.column.bg-main1[

### The Factorized Fixed Point

It is "easy to verify" that if all all clusters have the same average degree (number of edges), then $\mu_{iR}^{(s)} = \mu_{iR}^{(t)}$ is a fixed point of the BP dynamics. $\implies$ no information about clusters available. 

.alert[Key question]: is this fixed point stable?

.alert2[Standard method]: compute Jacobian matrix $\mathbf{J}$ of the dynamics at this fixed point and ask whether any $\lambda \geq 1$ for any eigenvalue $\lambda$ of $\mathbf{J}$. 

Corresponding eigenvectors give first-order perturbations away from the uninformative fixed point. 

]

.column[
  
  <br> <br> 

  "It turns out that"

  $$\mathbf{J} = \sum_{k = 1}^{\bar{k}} \mathbf{C}_k \otimes \mathbf{B}_k + O(n^{-1})\;,$$

  where: 

  - $\mathbf{C}_k$ is a matrix of parameters that depends on the statistical model $\mathbb{P}$. 
  - $\mathbf{B}_k$ is our friend the Hashimoto operator, restricted to edges of size $k$. 
  - $\otimes$ is the Kronecker product. 


<div class="footnote">
  .alert2[Shown for graphs by]: <br> Krzakala et al. (2013)  Spectral redemption in clustering sparse networks, <i>PNAS</i> 110 (52) 20935-20940
</div>

]

---

class: split-two

.column.bg-main1[

### Second Algorithm

1. Start with a guess about $\mathbf{C}_k$ and form 
$$\mathbf{J} = \sum_{k = 1}^{\bar{k}} \mathbf{C}_k \otimes \mathbf{B}_k\;.$$
2. Compute the leading $\ell$ eigenvectors of $\mathbf{J}$, provided they have real eigenvalues. 
3. For each eigenvector $\mathbf{v} = (\alpha, \beta)$, compute $u_{i\ell} = \mathbb{1}\left(\sum_{k = 1}^{\bar{k}} \alpha_{ik}^{(\ell)} > 0\right)$. 
4. Use a Euclidean clustering algorithm in the space spanned by the vectors $\{\mathbf{u}\}$. 
5. Re-estimate $\mathbf{C}_k$ and repeat...

Example: high-school contact hypergraph.

]

.column[.vmiddle[.center[

<img src="img/PCA.png" width=90%> 

]]]

---

class: split-two

# A Cheat

$\mathbf{J}$ is a *really* big matrix. 

As before, we can use a smaller one: 

**Theorem (PSC, JH, NE '21)**: Under mild conditions, if $\lambda$ is an "interesting" eigenvalue of $\mathbf{J},$ then $\lambda$ is also an eigenvalue of 

$$\mathbf{J}' = (\mathbf{G}\otimes \mathbf{I}_n) \left[\begin{matrix} 
\mathbf{0} & \mathbf{I}_\ell \otimes \bar{\mathbf{D}} \\ 
\mathbf{0} & \mathbf{I}_\ell \otimes \bar{\mathbf{A}}
\end{matrix}\right] - \bar{\mathbf{G}} \left[\begin{matrix} 
\mathbf{0} & \mathbf{I}_\ell \otimes \mathbf{I}_{\bar{k}} \\ 
\mathbf{I}_\ell \otimes (\mathbf{K} - \mathbf{I}_{\bar{k}-1}) & \mathbf{I}_\ell \otimes (\mathbf{K} - 2\mathbf{I}_{\bar{k}-1})
\end{matrix}\right] \otimes \mathbf{I}_n$$

**Proof Sketch**: 

---

class: split-two
background-image: url("img/scream.jpeg")
background-size: contain


---

class: split-two
layout: false

.column.bg-main1[
  ## Ok, but does it work? 

  Recall that we were having issues with situations in which edges of different sizes carried different kinds of information. 
]

.column[.vmiddle[.stretch[
  <img src="img/vanilla-heatmap.png" width=100%>   
]]]

---

class: split-two
layout: false

.column.bg-main1[
  ## Ok, but does it work? 

  Recall that we were having issues with situations in which edges of different sizes carried different kinds of information. 

<br> 

  Working with the more complicated matrix $\mathbf{J}$ increases computation time, but also allows us to detect clusters in these situations.  
]

.column[.vmiddle[.stretch[
  <img src="img/heatmap-exp-1.png" width=100%>   
]]]

---

class: split-two
layout: false

.column.bg-main1[
  ## Ok, but does it work? 

  Recall that we were having issues with situations in which edges of different sizes carried different kinds of information. 

<br> 

  Working with the more complicated matrix $\mathbf{J}$ increases computation time, but also allows us to detect clusters in these situations.  
]

.column[.vmiddle[.stretch[
  <img src="img/heatmap-exp-1-with-curve.png" width=100%>   
]]]


---


class: split-two
layout: false

.column.bg-main1[

# Summing Up

Hypergraphs have a .alert[rich detectability theory] which is still under development. 

Hypergraph nonbacktracking operators are likely to play a role in both theory and algorithms. 

.alert2[**There's lots left to be done!**]
- Thresholds with degree heterogeneity, more than 2 communities, etc. 
- **Conj**: failure of nonbacktracking methods coincides with fundamental .alert2[information-theoretic and computational thresholds].  
]

.column[

]

---

class: split-two
layout: false

.column.bg-main1[

# Summing Up

Hypergraphs have a .alert[rich detectability theory] which is still under development. 

Hypergraph nonbacktracking operators are likely to play a role in both theory and algorithms. 

.alert2[**There's lots left to be done!**]
- Thresholds with degree heterogeneity, more than 2 communities, etc. 
- **Conj**: failure of nonbacktracking methods coincides with fundamental .alert2[information-theoretic and computational thresholds].  
]

.column[
# **Thanks!!**

.row[ 
.split-two[
.column[.lil-stretch[<br><br><br><br> 
  <img src="img/jamie_portrait.jpeg" width=80%> 
  ]]
.column[.lil-stretch[<br><br><br><br>
  <img src="img/eikmeier-3.png" width=80%> 
]]]]
.row[ 
.split-two[
.column[.lil-stretch[<br><br><br><br><br><br><br><br><br><br>
  .alert[Jamie Haddock] <br> Harvey Mudd @jamie_hadd
  ]]
.column[.lil-stretch[<br><br><br><br><br><br><br><br><br><br>
  .alert[Nicole Eikmeier] <br> Grinnell @NicoleEikmeier
]]]]

<br><br><br><br><br><br><br><br><br>



- Leonie Neuhäuser 
- Christopher Blöcker
- Jürgen Hackl
- Y'all!! 

]]]



