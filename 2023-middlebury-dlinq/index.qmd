---
title: "A <span style='color:#EF476F'>Critical Citizen's</span> Guide to Large Language Models"  
subtitle: "Middlebury College DLINQ |  August 21st, 2023"  
date: ""
author: 'Dr. <span class="speaker-highlight">Phil Chodrow</span> <br>Department of Computer Science<br>Middlebury College'    
title-slide-attributes:
  data-background-opacity: "0.0"  
  data-background-color: "#23395B"  
format:
  revealjs:
    menu: false
    theme: 
      - default      
      - ../assets/reveal-style/layouts.css 
      - ../assets/reveal-style/components.css 
      - ../assets/reveal-style/colors-fonts/simple.scss
    slide-level: 2
    margin: 0.00
    self-contained: false
warning: false 
message: false
cache: true 
from: markdown+emoji
---



## {.split-40} 

<!-- quarto preview 2023-middlebury-dlinq/index.qmd-->

::: {.column .bg0}  
     
#### Hi! I'm Phil. 

I am an  [applied mathematician]{.alert}, <br>[data scientist]{.alert-2},<br> and [STEM educator]{.alert-3}.  

I like...

- Math models of social systems
- Statistics and machine learning
- Equity-oriented data science
- [Critical lenses on tech]{.fragment .bold}
- Traditional martial arts
- Tea
- *Star Trek: Deep Space 9*
- Effective pedagogy 

:::

::: {.column .bg0}


![](fig/phil.jpeg){.absolute top=-10 left=100 bottom=-20 height=940}

:::

## My Claims For You Today

<br> <br> <br> 

1. Large language models are trained to generate constructive, human-like text via prediction and reinforcement. 
3. People with profit and power motives are routinely lying to you about their capabilities. 
4. These models are driving large-scale degradation in online information ecosystems, labor stability, care resources, artistic production, and the environment.
5. Critical scholars -- especially Black women -- are showing the way 


## {.split-60}

:::: {.column}

### Large Language Models

<br>

:::{.font-larger} 

A ***language model*** is an algorithm that aims to generate [constructive]{.alert} [human-like]{.alert-2} text via two primary mechanisms: 

- **[Next-token prediction]{.alert-2}**
- **[Reinforcement learning with human feedback (RLHF)]{.alert}**

A language model is "***large***" when it is difficult to explain all of its behaviors purely in terms of structure and training ("*emergence*").

:::
::::

::: {.column}

![](fig/mayo.jpeg)

:::

## Next-Token Prediction

<br> 

::: {.center}

||||||
-|-|-|-|-|-|-
&nbsp;    | [artichoke]{.fragment .semi-fade-out fragment-index=2 .font-larger} |[the]{.fragment .semi-fade-out fragment-index=3 .font-larger} |[subtract]{.fragment .semi-fade-out fragment-index=4 .font-larger} |[college]{.fragment .semi-fade-out fragment-index=5 .font-larger} |[black]{.fragment .highlight-current-red fragment-index=6 .font-larger}   | [paint]{.fragment .semi-fade-out fragment-index=7 .font-larger} 
&nbsp;    | [boldly]{.fragment .semi-fade-out fragment-index=2 .font-larger} | [a]{.fragment .highlight-current-red fragment-index=3 .font-larger}  |[small]{.fragment .semi-fade-out fragment-index=4 .font-larger} |[but]{.fragment .semi-fade-out fragment-index=5 .font-larger} |[pinch]{.fragment .semi-fade-out fragment-index=6 .font-larger} | [pepper]{.fragment .highlight-current-red fragment-index=7 .font-larger} 
[Now]{.fragment .highlight-current-red fragment-index=1 .font-larger}  | [bubble]{.fragment .semi-fade-out fragment-index=2 .font-larger} |[Phil]{.fragment .semi-fade-out fragment-index=3 .font-larger} |[more]{.fragment .semi-fade-out fragment-index=4 .font-larger} |[add]{.fragment .semi-fade-out fragment-index=5 .font-larger} |[drink]{.fragment .semi-fade-out fragment-index=6 .font-larger} | [river]{.fragment .semi-fade-out fragment-index=7 .font-larger} 
&nbsp;    | [triangle]{.fragment .semi-fade-out fragment-index=2 .font-larger} |[draw]{.fragment .semi-fade-out fragment-index=3 .font-larger} |[bit]{.fragment .highlight-current-red fragment-index=4 .font-larger}  |[raisin]{.fragment .semi-fade-out fragment-index=5 .font-larger} |[cumin]{.fragment .semi-fade-out fragment-index=6 .font-larger} | [pinch]{.fragment .semi-fade-out fragment-index=7 .font-larger} 
&nbsp;    | [add]{.fragment .highlight-current-red fragment-index=2 .font-larger} | [escape]{.fragment .semi-fade-out fragment-index=2 .font-larger} |[lies]{.fragment .semi-fade-out fragment-index=4 .font-larger} |[of]{.fragment .highlight-current-red fragment-index=5 .font-larger}  |[jogging]{.fragment .semi-fade-out fragment-index=6 .font-larger} | [ice]{.fragment .semi-fade-out fragment-index=7 .font-larger} 
: {.borderless}

<br> 

||||||
-|-|-|-|-|-|-
[Now]{.fragment .highlight-current-red fragment-index=1 .font-larger}  | [add]{.fragment .fade-in  fragment-index=2 .font-larger} |[a]{.fragment .fade-in  fragment-index=3 .font-larger} |[bit]{.fragment .fade-in  fragment-index=4 .font-larger} |[of]{.fragment .fade-in  fragment-index=5 .font-larger} |[black]{.fragment .fade-in  fragment-index=6 .font-larger} | [pepper]{.fragment .fade-in  fragment-index=7 .font-larger} 

:::

<!-- ## {background-iframe="https://www.washingtonpost.com/technology/2023/06/02/ai-taking-jobs/"} -->

## Which response is better?


<br> 

["*First, whisk the eggs*."]{.fragment .fade-in .font-larger}

<br> 

[1. "Now add a bit of black [**pepper**]{.alert}"]{.font-larger}

[2. "Now add a bit of black [**paint**]{.alert-2}"]{.font-larger}

<br> 

[Reinforcement learning with human feedback (RLHF) encourages the model distinguish high-quality (helpful, non-offensive) responses.]{.fragment .fade-in .font-larger}

## 

![](fig/1-chatgpt-training.png)

*Image source: [Chip Huyen](https://huyenchip.com/2023/05/02/rlhf.html)*




## {.split-40}

::: {.column}

<br> <br> <br> 

*ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.*

:::

::: {.column}

![](fig/ai-is-work-verge.png){height = 800}

:::

![](fig/wsj-moderation-workforce.png){.fragment .absolute top=0}

## 

<br> <br> <br> <br> <br> <br> 

::: {.center}

[LLMs use next-token prediction to construct human-appearing sentences. RLHF steers those sentences towards being desirable (relevant, helpful, non-harmful).]{.font-larger}

:::

## {.split-50}

::: {.center}

### 65 Years of AI Hype

:::

## {.split-40} 

::: {.column}

<br> <br> <br> <br> <br> 

### Yes, LLMs are extremely impressive

:::

::: {.column}

![](fig/peanut-butter-sandwich.png)

:::

## {.split-50}


::: {.column}

![](fig/perceptron-nyt.jpeg){width=600}

\- NYT, 1958

:::

:::: {.column}

<!-- *It is not my aim to surprise or shock you—but the simplest way I can summarize is to say that there are now in the world machines that think,...*

\- Herbert Simon, 1958 -->

::: {.fragment}

<br> 

![](fig/linear-classifier.png)

*Image credit: [Wikipedia](https://en.wikipedia.org/wiki/Linear_classifier)* 

*This model is called the **perceptron***. 


:::
:::



## 

![](fig/bar-performance.png){.absolute top=20 height=700}

## 

![](fig/mit-curriculum.png){.absolute left=30 width=500}


![](fig/impossible-question.png){.absolute .fragment top=50 width=400 left=600}

![](fig/raunak-chowdhuri.png){.fragment .absolute bottom=50 width=500 left=300}





##

![](fig/bengali-1.png){.absolute top=20 width=400 left=300}
![](fig/bengali-2.png){.absolute .fragment top=20 width=400 left=300}



## {.split-33}

::: {.column}

<br> <br> <br> 

*Years of sociotechnical research show that advanced digital technologies, left unchecked, are used to pursue power and profit at the expense of human rights, social justice, and democracy.*

:::


::: {.column}

![](fig/lazar-nelson.png){width=500}

<!--  -->
:::


## {background-image="fig/openai-governance-doc.png"}

<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>
![](fig/openai-governance-excerpt.png){.absolute left=0 width=1500}


## 



![](fig/the%20future-comic.jpeg){.absolute top=50 left=300 height=600 }  

\@siyann_stuff

![](fig/wapo-jobs.png){.fragment .absolute top=20 fragment-index=2}

![](fig/eating-disorder-1.png){.fragment .absolute top=20 width=800 fragment-index=3}

![](fig/eating-disorder-2.png){.fragment .absolute top=300 width=800 fragment-index=3}

![](fig/eating-disorder-3.png){.fragment .absolute top=450 width=800 fragment-index=3}


## {.bg0}

### Outline

Introduction: 

- Me
- The phenomenon of LLMs

How LLMs work

- Next token prediction
- RLHF

Hype-people are lying to you

- Bengali
- MIT curriculum
- Lawyer

Social Impacts

- Labor
- Environment
- Artistic production
- Cultural representation

Think of commercial AI products as fossil fuels. 

- Fossil fuels are powerful but corrosive to the environmental fabric. 
- AI products are powerful but corrosive to the social fabric

Resist

- How can we teach students to resist the systems of power that are reinforced by AI systems?
- How can we teach students to be critical synthesizers of information in a world of disinformation?




## {.split-33 .bg0}  

::: {.column}

![](fig/water.jpeg)

:::

::: {.column}

<br> 

[*ChatGPT needs to “drink” a **500ml bottle of [[fresh]]{.alert} water** for a simple conversation of roughly 20-50 questions and answers, depending on when and where ChatGPT is deployed*.]{.font-larger .fragment .semi-fade-out}

[Roughly 1B visitors interacted with with the ChatGPT website in July, for 7 mins on average.]{.fragment}  

[If each one submitted **one query**, that's roughly 350K-850K liters of water per day.]{.fragment} 

[This is the drinking water need for roughly 100K-300K people.]{.fragment} 


[Li et al, arXiv preprint (2023)<br>
[https://www.similarweb.com/website/chat.openai.com/#overview](https://www.similarweb.com/website/chat.openai.com/#overview)]{.footnote}
:::




<!-- ::: {.column .bg0}  -->
<!-- more -->
<!-- ::: -->