---
title: "A <span style='color:#EF476F'>Critical Citizen's</span> Guide to Large Language Models"  
subtitle: "Middlebury College DLINQ |  August 21st, 2023"  
date: ""
author: 'Dr. <span class="speaker-highlight">Phil Chodrow</span> <br>Department of Computer Science<br>Middlebury College'    
title-slide-attributes:
  data-background-opacity: "0.0"  
  data-background-color: "#23395B"  
format:
  revealjs:
    menu: false
    theme: 
      - default      
      - ../assets/reveal-style/layouts.css 
      - ../assets/reveal-style/components.css 
      - ../assets/reveal-style/colors-fonts/simple.scss
    slide-level: 2
    margin: 0.00
    self-contained: false
warning: false 
message: false
cache: true 
from: markdown+emoji
---

## {.split-40} 

::: {.column .bg0}  
     
#### Hi! I'm Phil. 

I am an  [applied mathematician]{.alert}, <br>[data scientist]{.alert-2},<br> and [STEM educator]{.alert-3}.  

I like...

- Math models of social systems
- Statistics and machine learning
- Equity-oriented data science
- [Critical lenses on tech]{.fragment .bold}
- Traditional martial arts
- Tea
- *Star Trek: Deep Space 9*
- Effective pedagogy 

:::

::: {.column .bg0}


![](fig/phil.jpeg){.absolute top=-10 left=100 bottom=-20 height=940}

:::

## {.split-50}


::: {.column}

![](fig/perceptron-nyt.jpeg){width=600}

\- NYT, 1958

:::

:::: {.column}

<!-- *It is not my aim to surprise or shock you—but the simplest way I can summarize is to say that there are now in the world machines that think,...*

\- Herbert Simon, 1958 -->



::: {.fragment}

<br> 

![](fig/linear-classifier.png)

*Image credit: [Wikipedia](https://en.wikipedia.org/wiki/Linear_classifier)* 

:::

::::

## Large Language Models

A **language model** is an algorithm that aims to generate [constructive]{.alert} [human-like]{.alert-2} text via two primary mechanisms: 

- **[Next-token prediction]{.alert-2}**
- **[Reinforcement learning with human feedback (RLHF)]{.alert}**

A language model is "large" when it is difficult to explain all of its behaviors purely in terms of structure and training ("*emergence*").

## Next-Token Prediction

<br> <br> <br> <br> <br> <br> 

::: {.center}

[In]{.fragment .highlight-current-red .blur .big} &nbsp; 
[winter]{.fragment .highlight-current-red .blur .big} &nbsp;
[I]{.fragment .highlight-current-red .blur .big} &nbsp;
[like]{.fragment .highlight-current-red .blur .big} &nbsp;
[to]{.fragment .highlight-current-red .blur .big} &nbsp;
[drink]{.fragment .highlight-current-red .blur .big} &nbsp;
[hot]{.fragment .highlight-current-red .blur .big} &nbsp;
[coco]{.fragment .highlight-current-red .blur .big} &nbsp;   

:::


<!-- ## {background-iframe="https://www.washingtonpost.com/technology/2023/06/02/ai-taking-jobs/"} -->


##  

![](fig/wapo-jobs.png)

## {.split-50}

![](fig/the%20future-comic.jpeg) 

\@siyann_stuff

## {.split-40}

::: {.column}

<br> <br> <br> 

*ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.*

:::

::: {.column}

![](fig/ai-is-work-verge.png){height = 800}

:::

## {.bg0}

### Outline

Introduction: 

- Me
- The phenomenon of LLMs

How LLMs work

- Next token prediction
- RLHF

Hype-people are lying to you

- Bengali
- MIT curriculum
- Lawyer

Social Impacts

- Labor
- Environment
- Artistic production
- Cultural representation

Think of commercial AI products as fossil fuels. 

- Fossil fuels are powerful but corrosive to the environmental fabric. 
- AI products are powerful but corrosive to the social fabric

Resist

- How can we teach students to resist the systems of power that are reinforced by AI systems?
- How can we teach students to be critical synthesizers of information in a world of disinformation?




## {.bg0} 


<br> <br> <br> <br> <br> <br> 

::: {.center}

[In]{.fragment .highlight-current-red .blur .big} &nbsp; 
[winter]{.fragment .highlight-current-red .blur .big} &nbsp;
[I]{.fragment .highlight-current-red .blur .big} &nbsp;
[like]{.fragment .highlight-current-red .blur .big} &nbsp;
[to]{.fragment .highlight-current-red .blur .big} &nbsp;
[drink]{.fragment .highlight-current-red .blur .big} &nbsp;
[hot]{.fragment .highlight-current-red .blur .big} &nbsp;
[coco]{.fragment .highlight-current-red .blur .big} &nbsp;   

:::  

## {.split-33 .bg0}  

::: {.column}

![](fig/water.jpeg)

:::

::: {.column}

<br> 

[*ChatGPT needs to “drink” a **500ml bottle of [[fresh]]{.alert} water** for a simple conversation of roughly 20-50 questions and answers, depending on when and where ChatGPT is deployed*.]{.font-larger .fragment .semi-fade-out}

[Roughly 1B visitors interacted with with the ChatGPT website in July, for 7 mins on average.]{.fragment}  

[If each one submitted **one query**, that's roughly 350K-850K liters of water per day.]{.fragment} 

[This is the drinking water need for roughly 100K-300K people.]{.fragment} 


[Li et al, arXiv preprint (2023)<br>
[https://www.similarweb.com/website/chat.openai.com/#overview](https://www.similarweb.com/website/chat.openai.com/#overview)]{.footnote}
:::

## {.split-33}

::: {.column}

*Years of sociotechnical research show that advanced digital technologies, left unchecked, are used to pursue power and profit at the expense of human rights, social justice, and democracy.*

:::


::: {.column}

![](fig/lazar-nelson.png){width=500}

<!--  -->
:::


## Powerful People are Lying To You

![](fig/bar-performance.png)

## 

![](fig/bengali.png)



<!-- ::: {.column .bg0}  -->
<!-- more -->
<!-- ::: -->